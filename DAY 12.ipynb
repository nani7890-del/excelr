{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b73b49e",
   "metadata": {},
   "source": [
    "# DAY 12\n",
    "\n",
    "Write a Python script to generate a WordCloud from the text: 'data science machine learning artificial intelligence'. Save the WordCloud as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a97c34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\akash\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\akash\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\akash\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e11a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\akash\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: requests in c:\\users\\akash\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\akash\\anaconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\akash\\anaconda3\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\akash\\anaconda3\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\akash\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\akash\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\users\\akash\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\akash\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (2.10.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\akash\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\akash\\anaconda3\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\akash\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk requests beautifulsoup4 wordcloud matplotlib spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ceedd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akash\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "1: Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence.\n",
      "2: It focuses on the interaction between humans and computers using natural language.\n",
      "3: Tokenization is one of the fundamental steps in NLP, where text is broken down into sentences or words.\n",
      "\n",
      "\n",
      "Words:\n",
      "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'fascinating', 'field', 'of', 'Artificial', 'Intelligence', '.', 'It', 'focuses', 'on', 'the', 'interaction', 'between', 'humans', 'and', 'computers', 'using', 'natural', 'language', '.', 'Tokenization', 'is', 'one', 'of', 'the', 'fundamental', 'steps', 'in', 'NLP', ',', 'where', 'text', 'is', 'broken', 'down', 'into', 'sentences', 'or', 'words', '.']\n",
      "\n",
      "\n",
      "Cleaned Text:\n",
      "hello world welcome to nlp 101\n",
      "\n",
      "\n",
      "Extracted Emails:\n",
      "['support@example.com', 'sales@example.org']\n",
      "\n",
      "\n",
      "Webpage Title:\n",
      "Example Domain\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 56>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m wordcloud_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata science machine learning artificial intelligence\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 92\u001b[0m \u001b[43mgenerate_wordcloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwordcloud_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36mgenerate_wordcloud\u001b[1;34m(text, output_file)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_wordcloud\u001b[39m(text, output_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwordcloud.png\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate a WordCloud from the given text and save it as an image.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m     wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     wordcloud\u001b[38;5;241m.\u001b[39mto_file(output_file)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWordCloud saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:642\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    628\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \n\u001b[0;32m    630\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:624\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \n\u001b[0;32m    609\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m     font_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfrequencies\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;66;03m# find font sizes\u001b[39;00m\n\u001b[0;32m    456\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:511\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    508\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    509\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 511\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    514\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    515\u001b[0m                                    random_state)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "sample_paragraph = (\n",
    "    \"Natural Language Processing (NLP) is a fascinating field of Artificial Intelligence. \"\n",
    "    \"It focuses on the interaction between humans and computers using natural language. \"\n",
    "    \"Tokenization is one of the fundamental steps in NLP, where text is broken down into sentences or words.\"\n",
    ")\n",
    "\n",
    "def tokenize_sentences(paragraph):\n",
    "    return sent_tokenize(paragraph)\n",
    "\n",
    "def tokenize_words(paragraph):\n",
    "    return word_tokenize(paragraph)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove special characters and convert text to lowercase.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def extract_emails(text):\n",
    "    \"\"\"Extract all email addresses from the given text.\"\"\"\n",
    "    email_pattern = r'[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}'\n",
    "    return re.findall(email_pattern, text)\n",
    "\n",
    "def fetch_webpage_title(url):\n",
    "    \"\"\"Fetch and print the title of the given webpage.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return soup.title.string.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching webpage title: {e}\"\n",
    "\n",
    "def generate_wordcloud(text, output_file=\"wordcloud.png\"):\n",
    "    \"\"\"Generate a WordCloud from the given text and save it as an image.\"\"\"\n",
    "   \n",
    "    wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(text)\n",
    "    wordcloud.to_file(output_file)\n",
    "    print(f\"WordCloud saved as {output_file}\")\n",
    "    font_path = \"C:/Users/akash/Downloads/dejavu-fonts-ttf-2.37.tar.bz2\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sentences = tokenize_sentences(sample_paragraph)\n",
    "    print(\"Sentences:\")\n",
    "    for idx, sentence in enumerate(sentences, 1):\n",
    "        print(f\"{idx}: {sentence}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    words = tokenize_words(sample_paragraph)\n",
    "    print(\"Words:\")\n",
    "    print(words)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    test_text = 'Hello, World! Welcome to NLP 101.'\n",
    "    cleaned_text = clean_text(test_text)\n",
    "    print(\"Cleaned Text:\")\n",
    "    print(cleaned_text)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    email_text = 'Contact us at support@example.com and sales@example.org.'\n",
    "    emails = extract_emails(email_text)\n",
    "    print(\"Extracted Emails:\")\n",
    "    print(emails)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    url = 'https://example.com'\n",
    "    webpage_title = fetch_webpage_title(url)\n",
    "    print(\"Webpage Title:\")\n",
    "    print(webpage_title)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    wordcloud_text = 'data science machine learning artificial intelligence'\n",
    "    generate_wordcloud(wordcloud_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2681bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
